{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4Fmgui8/n9yOj5BN7r4hz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RidhoAnfaal/MachineLearning/blob/main/JS11_TG01_2341720222_Ridho_Anfa'al.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wC9CDIFGpph9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 1**"
      ],
      "metadata": {
        "id": "iNrfxwDxnSEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Import Libraries"
      ],
      "metadata": {
        "id": "o_78d1qvnZVS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sAtip_zm_sr"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Create Dummy Data"
      ],
      "metadata": {
        "id": "ww9_ZY_Ind3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X, y = make_blobs(n_samples=50, centers=2,\n",
        "                  random_state=0, cluster_std=0.60)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')"
      ],
      "metadata": {
        "id": "q7jNc0MinhWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Create Illustration of Decision Boundary"
      ],
      "metadata": {
        "id": "QRmyYnsmnwbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To construct a classification model, a decision boundary separating the two formed sets is required. However, this situation still leaves cases in which more than one decision boundary may be appropriate. The multiplicity of decision boundaries indicates several possible classifications for a new data point. A new data point 'x' may appear at a position different from those in the two existing sets and thus may not belong to either of the prior categories."
      ],
      "metadata": {
        "id": "eR2A4NJuozHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Margin Illustration"
      ],
      "metadata": {
        "id": "suXAQPVunuO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xfit = np.linspace(-1, 3.5)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "\n",
        "for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]:\n",
        "    yfit = m * xfit + b\n",
        "    plt.plot(xfit, yfit, '-k')\n",
        "    plt.fill_between(xfit, yfit - d, yfit + d, edgecolor='none',\n",
        "                     color='#AAAAAA', alpha=0.4)\n",
        "\n",
        "plt.xlim(-1, 3.5)"
      ],
      "metadata": {
        "id": "OQth0sqAnr88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Model Fitting"
      ],
      "metadata": {
        "id": "asdSQOF5o9Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC # \"Support vector classifier\"\n",
        "model = SVC(kernel='linear', C=1E10)\n",
        "model.fit(X, y)\n",
        "\n",
        "# create a function to display the data fit\n",
        "\n",
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # create a grid for model evaluation\n",
        "    x = np.linspace(xlim[0], xlim[1], 30)\n",
        "    y = np.linspace(ylim[0], ylim[1], 30)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.decision_function(xy).reshape(X.shape)\n",
        "\n",
        "    # plot boundary and margins\n",
        "    ax.contour(X, Y, P, colors='k',\n",
        "               levels=[-1, 0, 1], alpha=0.5,\n",
        "               linestyles=['--', '-', '--'])\n",
        "\n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(model)"
      ],
      "metadata": {
        "id": "qHGZBi-0o8FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "zCDD6vIppJpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_svm(N=10, ax=None):\n",
        "    X, y = make_blobs(n_samples=200, centers=2,\n",
        "                      random_state=0, cluster_std=0.60)\n",
        "    X = X[:N]\n",
        "    y = y[:N]\n",
        "    model = SVC(kernel='linear', C=1E10)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    ax = ax or plt.gca()\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    ax.set_xlim(-1, 4)\n",
        "    ax.set_ylim(-1, 6)\n",
        "    plot_svc_decision_function(model, ax)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "for axi, N in zip(ax, [60, 120]):\n",
        "    plot_svm(N, axi)\n",
        "    axi.set_title('N = {0}'.format(N))"
      ],
      "metadata": {
        "id": "dPMiHyCFpM5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the sample size may be chosen between 10 or 200 data points; no change to the model is observed\n",
        "\n",
        "from ipywidgets import interact, fixed\n",
        "interact(plot_svm, N=[10, 200], ax=fixed(None))"
      ],
      "metadata": {
        "id": "wFkFbuoppXNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 2**"
      ],
      "metadata": {
        "id": "xyhipGSHpgoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 - Illustration of Non-Linear Data**"
      ],
      "metadata": {
        "id": "eHkFGrNMpmst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1a - Import Libraries"
      ],
      "metadata": {
        "id": "wcYEUdZXqA39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "HjeYo0iGqMgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1b - Recreate the Plotting Function"
      ],
      "metadata": {
        "id": "bx-z0FMVqDGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to display model fitting\n",
        "\n",
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # create a grid for model evaluation\n",
        "    x = np.linspace(xlim[0], xlim[1], 30)\n",
        "    y = np.linspace(ylim[0], ylim[1], 30)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.decision_function(xy).reshape(X.shape)\n",
        "\n",
        "    # plot boundary and margins\n",
        "    ax.contour(X, Y, P, colors='k',\n",
        "               levels=[-1, 0, 1], alpha=0.5,\n",
        "               linestyles=['--', '-', '--'])\n",
        "\n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)"
      ],
      "metadata": {
        "id": "wWz4M3yLqN2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1c - Create Non-Linear Dummy Data"
      ],
      "metadata": {
        "id": "4-8LLQ85qHt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of non-linearly separable data\n",
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(100, factor=.1, noise=.1)\n",
        "\n",
        "clf = SVC(kernel='linear').fit(X, y)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf, plot_support=False);"
      ],
      "metadata": {
        "id": "Etmc5rUFqPHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Model Fitting"
      ],
      "metadata": {
        "id": "du3xRarQqJJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(kernel='rbf', C=1E6)\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "id": "zjfSDDMuqa-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf)\n",
        "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n",
        "            s=300, lw=1, facecolors='none')"
      ],
      "metadata": {
        "id": "VnrFhOcZqcRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 3**"
      ],
      "metadata": {
        "id": "lAbSiBJjqtTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Import Libraries and Create Plotting Function"
      ],
      "metadata": {
        "id": "US2v990nqxag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_blobs"
      ],
      "metadata": {
        "id": "DMQXr2HlqvYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to display the data fitting\n",
        "\n",
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # create a grid for model evaluation\n",
        "    x = np.linspace(xlim[0], xlim[1], 30)\n",
        "    y = np.linspace(ylim[0], ylim[1], 30)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.decision_function(xy).reshape(X.shape)\n",
        "\n",
        "    # plot boundary and margins\n",
        "    ax.contour(X, Y, P, colors='k',\n",
        "               levels=[-1, 0, 1], alpha=0.5,\n",
        "               linestyles=['--', '-', '--'])\n",
        "\n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)"
      ],
      "metadata": {
        "id": "Qv9mPZZYq1uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Create Dummy Data"
      ],
      "metadata": {
        "id": "C65L5TSAq2vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_blobs(n_samples=100, centers=2,\n",
        "                  random_state=0, cluster_std=1.2)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')"
      ],
      "metadata": {
        "id": "dPeQdqt_q3yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Analyze the Impact of Tuning"
      ],
      "metadata": {
        "id": "uI-oqXrxq6gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_blobs(n_samples=100, centers=2,\n",
        "                  random_state=0, cluster_std=0.8)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "\n",
        "for axi, C in zip(ax, [10.0, 0.1]):\n",
        "    model = SVC(kernel='linear', C=C).fit(X, y)\n",
        "    axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    plot_svc_decision_function(model, axi)\n",
        "    axi.scatter(model.support_vectors_[:, 0],\n",
        "                model.support_vectors_[:, 1],\n",
        "                s=300, lw=1, facecolors='none');\n",
        "    axi.set_title('C = {0:.1f}'.format(C), size=14)"
      ],
      "metadata": {
        "id": "WI7n_oJFq7cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 4**"
      ],
      "metadata": {
        "id": "-hzDXr8TrCY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0 - Download the Dataset"
      ],
      "metadata": {
        "id": "MpaqUcQbrE45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "faces = fetch_lfw_people(min_faces_per_person=60)\n",
        "print(faces.target_names)\n",
        "print(len(faces.target_names))\n",
        "print(faces.images.shape)"
      ],
      "metadata": {
        "id": "kbEP8c0KrEPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Inspect Facial Images"
      ],
      "metadata": {
        "id": "sApFhKUfrKKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example faces used\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(3, 5)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(faces.images[i], cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[],\n",
        "            xlabel=faces.target_names[faces.target[i]])"
      ],
      "metadata": {
        "id": "2G7CVCiprMjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Data Preprocessing"
      ],
      "metadata": {
        "id": "OuWWVJ2-rvFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA as RandomizedPCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
        "svc = SVC(kernel='rbf', class_weight='balanced')\n",
        "\n",
        "# Pipeline is used to perform processes sequentially in\n",
        "# a single function execution\n",
        "model = make_pipeline(pca, svc)"
      ],
      "metadata": {
        "id": "w0g54GU8ryDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Split Data"
      ],
      "metadata": {
        "id": "3WLk86nUrzKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separation of training and testing data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)"
      ],
      "metadata": {
        "id": "4DQbG6XQr1LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Model Creation + Tuning"
      ],
      "metadata": {
        "id": "v0_1e9jTr3Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'svc__C': [1, 5, 10, 50],\n",
        "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
        "grid = GridSearchCV(model, param_grid)\n",
        "\n",
        "%time grid.fit(Xtrain, ytrain)\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ],
      "metadata": {
        "id": "WgtSMAaur4Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = grid.best_estimator_\n",
        "yfit = model.predict(Xtest)"
      ],
      "metadata": {
        "id": "9dKPd4gwsnoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Check Prediction Results"
      ],
      "metadata": {
        "id": "EbhCsoxSsuPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels of the testing data\n",
        "\n",
        "fig, ax = plt.subplots(4, 6)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
        "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
        "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)"
      ],
      "metadata": {
        "id": "FOrLevk9svPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 - Check Performance"
      ],
      "metadata": {
        "id": "w2z_89D3syYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest, yfit,\n",
        "                            target_names=faces.target_names))"
      ],
      "metadata": {
        "id": "yIUwfDJJszuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "mat = confusion_matrix(ytest, yfit)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=faces.target_names,\n",
        "            yticklabels=faces.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')"
      ],
      "metadata": {
        "id": "lJ_MTDUitje4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 5**"
      ],
      "metadata": {
        "id": "b_9niAILvg_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0 - Import Libraries"
      ],
      "metadata": {
        "id": "OmsuYDWqxcpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libraries\n",
        "from pathlib import Path\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "U5ymJYR-xmXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image directories\n",
        "train_dir = \"/content/drive/MyDrive/ML/images/training\"\n",
        "test_dir = \"/content/drive/MyDrive/ML/images/test\""
      ],
      "metadata": {
        "id": "PjEbjsvgxoSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Load Data and Visualize"
      ],
      "metadata": {
        "id": "jvM6CtvTxnd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_dataset(img_dir):\n",
        "#     p = Path(img_dir)\n",
        "#     dirs = p.glob('*')\n",
        "\n",
        "#     img_list = []\n",
        "\n",
        "#     for dir in dirs:\n",
        "#         label = str(dir).split('/')[-1]\n",
        "#         for file in dir.glob('*.jpg'):\n",
        "#             img = mpimg.imread(file)\n",
        "\n",
        "#             if not img is None:\n",
        "#                 img_list.append((img, label))\n",
        "\n",
        "#     return img_list\n",
        "def load_dataset(img_dir):\n",
        "    p = Path(img_dir)\n",
        "\n",
        "    img_list = []\n",
        "    for class_folder in p.iterdir():\n",
        "        if class_folder.is_dir():\n",
        "            label = class_folder.name\n",
        "            for ext in ['*.jpg','*.JPG','*.jpeg','*.JPEG','*.png','*.PNG']:\n",
        "                for file in class_folder.glob(ext):\n",
        "                    # skip mac metadata files\n",
        "                    if file.name.startswith(\"._\"):\n",
        "                        continue\n",
        "                    try:\n",
        "                        img = cv2.imread(str(file))\n",
        "                        if img is not None:\n",
        "                            img_list.append((img, label))\n",
        "                    except:\n",
        "                        pass\n",
        "    return img_list"
      ],
      "metadata": {
        "id": "UmZcDh40zviS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load training data\n",
        "# train_img = load_dataset(train_dir)\n",
        "train_img = load_dataset(train_dir)\n",
        "print(\"Loaded images =\", len(train_img))"
      ],
      "metadata": {
        "id": "t0h6rFMezyvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cls in [\"night\",\"day\"]:\n",
        "    folder = Path(train_dir) / cls\n",
        "    print(\"Folder:\", cls)\n",
        "    print([f.name for f in folder.iterdir()])"
      ],
      "metadata": {
        "id": "65vSBuxu45WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first data\n",
        "# It should be a tuple consist of arrays of image and image labels\n",
        "train_img[0]"
      ],
      "metadata": {
        "id": "ULnm8ndu0mGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random size checking\n",
        "pick_random = np.random.randint(0, len(train_img))\n",
        "\n",
        "# Check img size\n",
        "print(f'Image {pick_random}')\n",
        "print(train_img[pick_random][0].shape)"
      ],
      "metadata": {
        "id": "1h6PzHGAORdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Visualize\n",
        "def random_img_viz(img_list):\n",
        "    rand_num = np.random.randint(0, len(img_list))\n",
        "\n",
        "    img = img_list[rand_num][0]\n",
        "    label = img_list[rand_num][1]\n",
        "    label_str = 'day' if label == 1 else 'night'\n",
        "\n",
        "    plt.imshow(img)\n",
        "    print(f'Shape\\t: {img.shape}')\n",
        "    print(f'Label\\t: {label}')"
      ],
      "metadata": {
        "id": "KhNopB1rOaxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_img_viz(train_img)"
      ],
      "metadata": {
        "id": "YeWIWOujOb8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Data Preprocessing"
      ],
      "metadata": {
        "id": "m6uAebEFOk8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standarized_input(image):\n",
        "    # resize to w: 1100, h:600\n",
        "    std_img = cv2.resize(image, (1100,600))\n",
        "\n",
        "    return std_img"
      ],
      "metadata": {
        "id": "LayVkj9POmBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoder(label):\n",
        "    # Encode the label\n",
        "    # day as 1; night as 0\n",
        "    num_val = 0\n",
        "\n",
        "    if(label == 'day'):\n",
        "        num_val = 1\n",
        "\n",
        "    return num_val"
      ],
      "metadata": {
        "id": "lmCiilFpOndt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img_list):\n",
        "    std_img_list = []\n",
        "\n",
        "    for item in img_list:\n",
        "        image = item[0]\n",
        "        label = item[1]\n",
        "\n",
        "        # Standarized the image\n",
        "        std_img = standarized_input(image)\n",
        "\n",
        "        # Create the label\n",
        "        img_label = label_encoder(label)\n",
        "\n",
        "        std_img_list.append((std_img, img_label))\n",
        "\n",
        "    return std_img_list"
      ],
      "metadata": {
        "id": "oZeBN6tiOolH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_std_img_list = preprocess(train_img)"
      ],
      "metadata": {
        "id": "QbRpexv7O4Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random size checking\n",
        "pick_random = np.random.randint(0, len(train_std_img_list))\n",
        "\n",
        "# Check img size\n",
        "print(f'Image {pick_random}')\n",
        "print(train_std_img_list[pick_random][0].shape)"
      ],
      "metadata": {
        "id": "1efuw3TMO5Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Feature Extraction"
      ],
      "metadata": {
        "id": "At8bZvgHPBys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature based on average brightness using HSV colorspace\n",
        "def avg_brightness(image):\n",
        "    # Convert image to HSV\n",
        "    img_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Calculate the avg of brightness\n",
        "    sum_brightness = np.sum(img_hsv[:,:,2]) # take the 3rb value which is the V channel\n",
        "    area = image.shape[0] * image.shape[1]\n",
        "    avg = sum_brightness / area\n",
        "\n",
        "    return avg"
      ],
      "metadata": {
        "id": "HiiyVWKtPCsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check on random image\n",
        "rand_img = np.random.randint(0, len(train_std_img_list))\n",
        "\n",
        "feature_img = train_std_img_list[rand_img][0]\n",
        "\n",
        "avg_img = avg_brightness(feature_img)\n",
        "\n",
        "print(f'Image {rand_img}')\n",
        "print(f'Avg Brighness: {avg_img:.4f}')\n",
        "plt.imshow(feature_img)"
      ],
      "metadata": {
        "id": "EMzGF4aDPF1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Classification using Threshold Method"
      ],
      "metadata": {
        "id": "z0YRFjVRPI0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(img, threshold):\n",
        "    # Computer average brightness\n",
        "    avg = avg_brightness(img)\n",
        "    pred = 0\n",
        "\n",
        "    # Predict the label based on user defined threshold\n",
        "    if avg > threshold:\n",
        "        pred = 1\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "IE_MvwZQPJuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the classifier on train data\n",
        "rand_img = np.random.randint(0, len(train_std_img_list))\n",
        "\n",
        "pred = predict_label(train_std_img_list[rand_img][0], threshold=120)\n",
        "\n",
        "# Evaluate\n",
        "print(f'Image {rand_img}')\n",
        "print(f'Actual label: {train_std_img_list[rand_img][1]}')\n",
        "print(f'Predicted label: {pred}')\n",
        "plt.imshow(train_std_img_list[rand_img][0])"
      ],
      "metadata": {
        "id": "-w0VVKXsPLcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 - Manual Evaluation"
      ],
      "metadata": {
        "id": "PUjpyifEPRII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(img_list, threshold):\n",
        "    miss_labels = []\n",
        "\n",
        "    for file in img_list:\n",
        "        # Get the ground truth / correct label\n",
        "        img = file[0]\n",
        "        label = file[1]\n",
        "\n",
        "        # Get prediction\n",
        "        pred_label = predict_label(img, threshold)\n",
        "\n",
        "        # Compare ground truth and pred\n",
        "        if pred_label != label:\n",
        "            miss_labels.append((img, pred_label, label))\n",
        "\n",
        "    total_img = len(img_list)\n",
        "    corr_pred = total_img - len(miss_labels)\n",
        "    accuracy = corr_pred / total_img\n",
        "\n",
        "    print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "zXgb1A5YPS9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on train data\n",
        "evaluate(train_std_img_list, threshold=120)"
      ],
      "metadata": {
        "id": "E5OzbuB4PUZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "\n",
        "# Load test data\n",
        "test_img = load_dataset(test_dir)\n",
        "\n",
        "# Preprocess\n",
        "test_std_img_list = preprocess(test_img)\n",
        "\n",
        "# Predict\n",
        "evaluate(test_std_img_list, threshold=120)"
      ],
      "metadata": {
        "id": "Yl188_UMPVjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification with SVM"
      ],
      "metadata": {
        "id": "_BLAtGdBPiUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative Step 4 - Constructing Feature Vectors."
      ],
      "metadata": {
        "id": "5XLpgR5QPjoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to extract feature for every images and stored in tabular data\n",
        "# Stored in Pandas dataframe\n",
        "def extract_avg_bright_feature(img_list):\n",
        "    avg_list = []\n",
        "    labels = []\n",
        "\n",
        "    for img in img_list:\n",
        "        img_avg = avg_brightness(img[0]) # Get the avg brightness from image\n",
        "        img_label = img[1] # Get the image label\n",
        "\n",
        "        avg_list.append(img_avg)\n",
        "        labels.append(img_label)\n",
        "\n",
        "    # Stack data in columcular way\n",
        "    data = np.column_stack((avg_list, labels))\n",
        "    # Create a Pandas dataframe\n",
        "    df = pd.DataFrame(data, columns=['AVG_BRIGHT', 'LABELS'])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "7wvUrONIPl51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract feature on train data\n",
        "train_avg_img = extract_avg_bright_feature(train_std_img_list)\n",
        "print(f'Shape: {train_avg_img.shape}')\n",
        "train_avg_img.head()"
      ],
      "metadata": {
        "id": "LvHcvFwoPm7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the same thing on test data\n",
        "test_avg_img = extract_avg_bright_feature(test_std_img_list)\n",
        "print(f'Shape: {test_avg_img.shape}')\n",
        "test_avg_img.head()"
      ],
      "metadata": {
        "id": "P5DIX36CPoEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Build SVM Model"
      ],
      "metadata": {
        "id": "jktS2ZcYPpg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requied library\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Split data and label\n",
        "X_train = train_avg_img.iloc[:,0].values.reshape(-1,1)\n",
        "y_train = train_avg_img.iloc[:,1]\n",
        "X_test = test_avg_img.iloc[:,0].values.reshape(-1,1)\n",
        "y_test = test_avg_img.iloc[:,1]\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "A3CjJd4kPpLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 - Evaluation"
      ],
      "metadata": {
        "id": "bwtY0ddJPsxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make a prediction on train data\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Get the accuracy on train data\n",
        "acc_train = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "# Make a prediction on test data\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Get the accuracy on test data\n",
        "acc_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Print Eval Result\n",
        "print(f'Accuracy on train: {acc_train}')\n",
        "print(f'Accuracy on test: {acc_test}')"
      ],
      "metadata": {
        "id": "QEzNfmdhPt7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab Assignment**"
      ],
      "metadata": {
        "id": "04jwQtN9P3Xw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Construct an SVM model using the data voice.csv under the following conditions,\n",
        "\n",
        "a. Split the data using ratios of 70:30 and 80:20 for each model to be developed.\n",
        "\n",
        "i. Use a model with a linear kernel.\n",
        "\n",
        "ii. Use a model with a polynomial kernel.\n",
        "\n",
        "iii. Use a model with an RBF kernel.\n",
        "\n",
        "b. Tabulate the performance of each split and kernel based on the accuracy metric."
      ],
      "metadata": {
        "id": "lyWVtE-kWGqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ML/voice.csv\")\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"label\"] = le.fit_transform(df[\"label\"])\n",
        "\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "def evaluate_svm(test_ratio):\n",
        "    results = {}\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=test_ratio, random_state=42\n",
        "    )\n",
        "\n",
        "    for kernel in [\"linear\", \"poly\", \"rbf\"]:\n",
        "        svm_model = SVC(kernel=kernel)\n",
        "        svm_model.fit(X_train, y_train)\n",
        "        pred = svm_model.predict(X_test)\n",
        "        results[kernel] = accuracy_score(y_test, pred)\n",
        "\n",
        "    return results\n",
        "\n",
        "results_70 = evaluate_svm(0.30)\n",
        "results_80 = evaluate_svm(0.20)\n",
        "\n",
        "print('70:80 :', results_70)\n",
        "print('80:20 :', results_80)"
      ],
      "metadata": {
        "id": "jm8EgiPyTQkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 conclusion : For the 70:30 split, the accuracies for the linear, polynomial, and RBF kernels were 0.9706, 0.9569, and 0.9811, respectively. In the case of the 80:20 split, the same kernel order resulted in accuracies of 0.9763, 0.9685, and 0.9826. The RBF kernel was found to be superior in terms of accuracy across both split ratios, while the polynomial kernel was the least effective. The increase of the training data proportion from 70% to 80% indicated a slight improvement in the classification performance, showing that the predictive capability of all models was stable and strong."
      ],
      "metadata": {
        "id": "Ace30zopj7ZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use the data from practical session 5 to develop a daytime and nighttime classification model using an SVM with an RBF kernel employing histogram features. Use an 80:20 ratio. You may experiment with hyperparameter tuning of the RBF kernel. Record the accuracy performance!"
      ],
      "metadata": {
        "id": "wzkMDafeWGI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def extract_histogram(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "\n",
        "    hist = []\n",
        "    for i in range(3):\n",
        "        h = cv2.calcHist([img], [i], None, [256], [0, 256])\n",
        "        hist.extend(h.flatten())\n",
        "    return np.array(hist)\n",
        "\n",
        "def load_dataset(folder_path):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for label, folder in enumerate([\"day\", \"night\"]):\n",
        "        folder_dir = os.path.join(folder_path, folder)\n",
        "        for file in tqdm(os.listdir(folder_dir), desc=f\"Loading {folder} images\"):\n",
        "            img_path = os.path.join(folder_dir, file)\n",
        "            features = extract_histogram(img_path)\n",
        "            X.append(features)\n",
        "            y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/ML/images/training\"\n",
        "test_path  = \"/content/drive/MyDrive/ML/images/test\"\n",
        "\n",
        "X_train_full, y_train_full = load_dataset(train_path)\n",
        "X_test, y_test = load_dataset(test_path)"
      ],
      "metadata": {
        "id": "knDmshMbfPzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
        ")\n",
        "\n",
        "svm_rbf = SVC(kernel='rbf')\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_rbf.predict(X_val)\n",
        "baseline_acc = accuracy_score(y_val, y_pred)\n",
        "print(\"Baseline RBF Accuracy:\", baseline_acc)"
      ],
      "metadata": {
        "id": "iFXwqb5EfuPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"C\": [0.1, 1, 10, 100],\n",
        "    \"gamma\": [\"scale\", 0.01, 0.001, 0.0001]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SVC(kernel='rbf'), params, cv=3, n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "\n",
        "best_svm = grid.best_estimator_\n",
        "y_pred_tuned = best_svm.predict(X_val)\n",
        "tuned_acc = accuracy_score(y_val, y_pred_tuned)\n",
        "print(\"Tuned Model Accuracy:\", tuned_acc)"
      ],
      "metadata": {
        "id": "E8I_iUwXfzzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_svm.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Final Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "O9c1foSFf3mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question number 2 conclusion : RBF-SVM model got an accuracy of 1.0 on the validation set. The best parameters (C = 10, gamma = scale) were determined after hyperparameter tuning with GridSearchCV, keeping a validation accuracy of 1.0. Testing on the data that was not seen before gave an accuracy of 0.975, indicating that day and night images were classified effectively with very little loss in performance."
      ],
      "metadata": {
        "id": "V0AYxFI-gxh9"
      }
    }
  ]
}